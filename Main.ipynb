{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Basic tutorial on moving from previous iterations to TF2\n",
    "## This assumes you are already using many of the older packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing data\n",
    "## First, lets import a few tools that we will need, these include the Dicom_RT_Images_to_Mask which will read our data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Base_Deeplearning_Code.Dicom_RT_and_Images_to_Mask.Image_Array_And_Mask_From_Dicom_RT import Dicom_to_Imagestack, os\n",
    "from Base_Deeplearning_Code.Plot_And_Scroll_Images.Plot_Scroll_Images import plot_scroll_Image, plot_Image_Scroll_Bar_Image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dicom_image_path = r'\\\\mymdafiles\\di_data1\\Morfeus\\BMAnderson\\CNN\\Data\\Data_Liver\\Miccai_Challenge\\Images'\n",
    "out_path = r'D:\\Test'\n",
    "description = 'Explanation'\n",
    "excel_file = os.path.join('.','distribution.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lets see what contours we have"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reader = Dicom_to_Imagestack(get_images_mask=False)\n",
    "reader.down_folder(dicom_image_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Print all rois that have something with \"liver\" in them')\n",
    "for roi in reader.all_rois:\n",
    "    if roi.lower().find('liver') != -1:\n",
    "        print(roi)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Lets just take the liver contours...')\n",
    "reader.set_contour_names(['Liver'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now, we've told the reader that we want every exam with a liver in it, if the contour does not exist, it will tell us"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reader.set_contour_names(['Liver_BMA_Program'])\n",
    "reader.down_folder(dicom_image_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lets write the data out now"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Writing out data')\n",
    "reader.set_contour_names(['Liver'])\n",
    "reader.set_description()\n",
    "reader.write_parallel(out_path=out_path, excel_file=excel_file)\n",
    "print('Finished!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now distribute them, either manually or with the distribute function into Train, Test, and Validation folders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Base_Deeplearning_Code.Dicom_RT_and_Images_to_Mask.Distribute_Train_Test_Validation import distribute\n",
    "distribute(description=description,niftii_path=out_path, excel_file=excel_file)\n",
    "print('Finished!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Turning data into tfrecord\n",
    "## We will be training a 2D segmentation algorithm, so we want our training to be 2D slices\n",
    "## But for validation we will want to predict on the entire image, so they will be 3D"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Base_Deeplearning_Code.Make_Single_Images.Make_TFRecord_Class import write_tf_record, os\n",
    "train_path = os.path.join(out_path,description,'Train')\n",
    "test_path = os.path.join(out_path,description,'Test')\n",
    "validation_path = os.path.join(out_path,description,'Validation')\n",
    "write_tf_record(path=train_path,is_3D=False, extension=0)\n",
    "write_tf_record(path=validation_path,is_3D=True)\n",
    "write_tf_record(path=test_path,is_3D=True)\n",
    "print('Finished writing records')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now our record files exist, along with a .pkl file that will be used to decode, and a Num_Examples so we can keep count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Next lets write out generators"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from Base_Deeplearning_Code.Data_Generators.Generator_TF_Record import Data_Generator_Class\n",
    "from Base_Deeplearning_Code.Data_Generators.Image_Processors_TF import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load in the image processors that we want and the data generator class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_record = os.path.join(train_path,'Record_2D.tfrecord')\n",
    "train_generator = Data_Generator_Class([train_record])\n",
    "num_examples = len(train_generator)\n",
    "print('The generator has {} examples'.format(len(train_generator)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now we will load up image processors, this will convert our raw data into whatever we want"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Recommend always starting with these, it will decode and return images and annotations')\n",
    "\n",
    "image_processors = [Decode_Images_Annotations(),\n",
    "                    Decode_Bounding_Boxes_Volumes_Spacing(),\n",
    "                    Return_Images_Annotations()]\n",
    "train_generator.compile_data_set(image_processors=image_processors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lets see what we got!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = next(iter(train_generator.data_set))\n",
    "print(data)\n",
    "print('As you can see, this is returning two 512x512 arrays, the first being our image, and the second being our mask')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lets add a few more processors to make this better..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_record = os.path.join(train_path,'Record_2D.tfrecord')\n",
    "train_generator = Data_Generator_Class([train_record])\n",
    "image_processors = [Decode_Images_Annotations(),\n",
    "                    Decode_Bounding_Boxes_Volumes_Spacing(),\n",
    "                    Return_Images_Annotations(),\n",
    "                    Expand_Dimensions(axis=-1, on_images=True, on_annotations=True),\n",
    "                    Ensure_Image_Proportions(tf.constant(512)),\n",
    "                    Normalize_Images(mean_val=80, std_val=30),\n",
    "                    Threshold_Images(lower_bound=-10, upper_bound=10),\n",
    "                    {'cache'},\n",
    "                    {'shuffle':len(train_generator)},\n",
    "                    {'batch':10},\n",
    "                    {'repeat'}]\n",
    "train_generator.compile_data_set(image_processors=image_processors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('The generator has {} examples'.format(len(train_generator)))\n",
    "data = next(iter(train_generator.data_set))\n",
    "# print(data)\n",
    "print('As you can see, this is returning two 512x512 arrays, the first being our image, and the second being our mask')\n",
    "images, annotation = data[0].numpy(), data[1].numpy()\n",
    "annotation *= np.max(images)\n",
    "data = np.concatenate([np.squeeze(images),np.squeeze(annotation)],axis=1)\n",
    "plot_Image_Scroll_Bar_Image(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lastly, lets look at our validation data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validation_record = os.path.join(validation_path,'Record_3D.tfrecord')\n",
    "validation_generator = Data_Generator_Class([validation_record])\n",
    "image_processors = [Decode_Images_Annotations(),\n",
    "                    Decode_Bounding_Boxes_Volumes_Spacing(),\n",
    "                    Return_Images_Annotations(),\n",
    "                    Expand_Dimensions(axis=-1, on_images=True, on_annotations=True),\n",
    "                    Ensure_Image_Proportions(tf.constant(512)),\n",
    "                    Normalize_Images(mean_val=80, std_val=30),\n",
    "                    Threshold_Images(lower_bound=-10, upper_bound=10),\n",
    "                    {'cache'},\n",
    "                    {'repeat'}]\n",
    "validation_generator.compile_data_set(image_processors=image_processors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('The generator has {} examples'.format(len(train_generator)))\n",
    "data = next(iter(validation_generator.data_set))\n",
    "# print(data)\n",
    "print('As you can see, this is returning two 512x512 arrays, the first being our image, and the second being our mask')\n",
    "images, annotation = data[0].numpy(), data[1].numpy()\n",
    "annotation *= np.max(images)\n",
    "data = np.concatenate([np.squeeze(images),np.squeeze(annotation)],axis=1)\n",
    "plot_Image_Scroll_Bar_Image(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feel free to make any processor that you want, you can see the basic format in the top of Image_Processors_TF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}